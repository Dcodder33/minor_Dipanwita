Abstract:
	Today, internet has transformed the way we shop, with a vast selection of products available for purchase online. However this convenience comes at a cost, with customers having to sort through countless options, thereby making it an overwhelming and tiring task.
	To simplify this sorting process, a Recommendation System powered by Artificial Intelligence van efficiently provide personalized recommendations to users. This system used machine learning algorithms that analyse user data, such as search history, purchase behaviour, and preferences, to predict what product the user is interested in. 
        It  saves time and effort by tailoring suggestions matching the customer’s interests and preferences. This system also encourages the customers to purchase more products, thereby increasing the revenue and profits of the sellers.
	Recommendation System for Electronic Appliances uses artificial intelligence techniques to deliver personalized product suggestions. By analyzing user preferences, browsing behaviour, and purchase history, the system will generate personalized recommendations that align with individual needs and budgets. 
        The System also incorporates real-time contextual data, such as user location and seasonal trends to further refine the suggestions.
	In this recommendation system, we will be using the matrix factorization with Alternating Least Square(ALS) algorithm to calculate the latent features of users and electronic appliances. The ALS algorithm approximates the sparse user-item rating matrix as the product of two dense matrices: the user factor matrix and the item factor matrix. 
        These matrices represent the hidden features of users and items, with dimensions corresponding to the number of users, items, and latent features.
        By iteratively optimizing one matrix, while keeping the other fixed, the ALS algorithm discovers numeric factors for each user and item. 
        This process continues until the algorithm converges, enabling accurate prediction of user preferences for unseen items.
	To enhance the accuracy and relevance of recommendations, we have incorporated the Wide and Deep Learning model. This model combines the strengths of two complementary models: Wide model and Deep model.
  
Wide Model for Memorization : Captures simple feature interactions through generalized linear model, effectively memorizing patterns like feature co-occurrences.
Deep Model for Generalization : A Dense Neural Network with multiple hidden layers, learns complex, nonlinear relationships by embedding categorical variables into continuous vectors. It generalizes well to unseen items by discovering intricate patterns and relationships in data.
The combination of the two ensures system can simultaneously “memorize” known relationships and “generalize” to new scenarios. 

# Recommendation system are mainly of three types ie 

1)Collaborative - Focuses on user preference and behaviour ie user interaction with products and choices made here we mostly use cosine similarity.
  If the cosine similarity is 1, it means the vectors have the same direction and are perfectly similar.
  If the cosine similarity is 0, it means the vectors are perpendicular to each other and have no similarity.
  If the cosine similarity is -1, it means the vectors have opposite directions and are perfectly dissimilar.
2)Content- Focuses on attributes like cose,quality,features,brand
3)Hybrid- Uses both feature of content and collaborative.

# Some of the Different Similarities 

1) Cosine similarity - measure of similarity between two non-zero vectors n-dimensional space. 
   Cosine similarity is often used in text-based data, where it helps measure the similarity of two documents or items based on their features (e.g., ratings, keywords). 
   Formula:Cosine Similarity (A, B) = (A · B) / (||A|| * ||B||)
   ||A|| represents the Euclidean norm (magnitude) of vector A, which is the square root of the sum of the squares of its components. 
   It’s calculated as ||A|| = √(A₁² + A₂² + … + Aₙ²). ||B|| represents the Euclidean norm (magnitude) of vector B, calculated in the same way as ||A||.

2) Euclidean Distance - Measures the "straight line" distance between two points (vectors) in Euclidean space. It's often used in clustering and anomaly detection.
   Euclidean distance is useful when comparing continuous data, such as measurements in feature space or when clustering.
   Formula:Distance(A,B)= √ Σ(A(i)-B(i))^2 for i=1 to n
   A and B are two vectors.
   A(i) and B(i) are the corresponding components of vectors 

3) Pearson Correlation -  Measures the linear correlation between two variables. It is widely used in collaborative filtering to determine how similarly two users rate items.
   Pearson correlation is particularly useful in collaborative filtering where ratings are sparse and want to measure how similarly two users behave (e.g., ratings of products).
   Formula:Similarity(A,B)=Σ(A(i)-mean A(i))*(B(i)-mean B(i))/√ (Σ((A(i)-mean A(i))^2)* √( Σ(B(i)-mean B(i))^2)
# Dataset Updation
import pandas as pd
data = pd.read_csv('ndtv_data_final.csv')
reviews = [
    "Excellent performance, worth the price.",
    "Great battery life, perfect for gaming.",
    "Amazing camera quality, a bit expensive.",
    "Good value for money, smooth performance.",
    "Battery could be better, decent overall.",
    "Highly recommend for photography lovers.",
    "Affordable and reliable, good screen quality.",
    "Sleek design, average battery life.",
    "Perfect for everyday use, budget-friendly.",
    "Premium quality, outstanding features."
]
expanded_reviews = reviews * (len(data)) // len(reviews)) + reviews[:len(data) % len(reviews)]
data['Customer Reviews'] = expanded_reviews
updated_file_path = 'ndtv_data_with_reviews.csv'
data.to_csv(updated_file_path, index=False)

   
